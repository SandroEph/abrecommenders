# A/B Recommenders
An end-to-end implementation of online recommender systems A/B testing

## Table of contents
* [Introduction](#introduction)
* [Background](#background)
* [Objective](#objectives)
* [Business Case](#business-case)
* [System design](#system-design)
* [Tools and packages](#tools-and-packages)
* [Data](#data)
* [Data preprocessing](#data-preprocessing)
* [Recommender system](#recommender-system)
* [Recommender system results](#recommender-system-results)
* [Experiment design](#experiment-design)
* [Integration and deployment](#integration-and-deployment)
* [Results](#results)
* [Conclusion](#conclusion)
* [References](#references)
* [Challenges and future work](#challenges-and-future-work)

## Introduction

This is the first repository/tutorial from a series of others where I challenge myself to build, deploy and 
explain an end to end data science solution to a concrete business use case.

## Background

This project is inspired from a question I was asked during an interview : 
> How would you compare the performance of two recommender systems in production ?

I knew the theoretical answer to this question but found that I lacked some of the 
practical skills that would allow me to solve this problem and implement its solution in production.


## Objectives

#### Main objective :
Design and deploy an A/B test experiment evaluating and comparing the online performance of two different recommender systems.
#### Secondary objectives : 
* Design and train a recommender system model
* Develop and deploy a proof of concept product website to run the experiment
* Automate the experiment for testing purposes

## Business Case

## System design

## Tools and packages

## Data

## Data preprocessing

## Recommender system

## Recommender system results

## Experiment design

## Integration and deployment

## Results

## Conclusion

## References

## Challenges and future work
ðŸš§ In progress ðŸš§